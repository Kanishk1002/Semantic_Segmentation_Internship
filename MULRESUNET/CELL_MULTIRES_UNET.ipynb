{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOQY/dkBw1nMuHWkXFRJlzn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDwTjE9VRVsH","executionInfo":{"status":"ok","timestamp":1689441392925,"user_tz":-330,"elapsed":83624,"user":{"displayName":"VANGA KANISHKA NADH","userId":"15191267719021947787"}},"outputId":"26a1d7cc-a65b-4a29-b778-198fda1f7c0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Conv2DTranspose\n","from tensorflow.keras.layers import Concatenate, Input\n","from tensorflow.keras.models import Model\n","\n","def conv_block(x, num_filters, kernel_size, padding=\"same\", act=True):\n","    x = Conv2D(num_filters, kernel_size, padding=padding, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    if act:\n","        x = Activation(\"relu\")(x)\n","    return x\n","\n","def multires_block(x, num_filters, alpha=1.67):\n","    W = num_filters * alpha\n","\n","    x0 = x\n","    x1 = conv_block(x0, int(W*0.167), 3)\n","    x2 = conv_block(x1, int(W*0.333), 3)\n","    x3 = conv_block(x2, int(W*0.5), 3)\n","    xc = Concatenate()([x1, x2, x3])\n","    xc = BatchNormalization()(xc)\n","\n","    nf = int(W*0.167) + int(W*0.333) + int(W*0.5)\n","    sc = conv_block(x0, nf, 1, act=False)\n","\n","    x = Activation(\"relu\")(xc + sc)\n","    x = BatchNormalization()(x)\n","    return x\n","\n","def res_path(x, num_filters, length):\n","    for i in range(length):\n","        x0 = x\n","        x1 = conv_block(x0, num_filters, 3, act=False)\n","        sc = conv_block(x0, num_filters, 1, act=False)\n","        x = Activation(\"relu\")(x1 + sc)\n","        x = BatchNormalization()(x)\n","    return x\n","\n","def encoder_block(x, num_filters, length):\n","    x = multires_block(x, num_filters)\n","    s = res_path(x, num_filters, length)\n","    p = MaxPooling2D((2, 2))(x)\n","    return s, p\n","\n","def decoder_block(x, skip, num_filters):\n","    x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(x)\n","    x = Concatenate()([x, skip])\n","    x = multires_block(x, num_filters)\n","    return x\n","\n","def build_multiresunet(shape):\n","    \"\"\" Input \"\"\"\n","    inputs = Input(shape)\n","\n","    \"\"\" Encoder \"\"\"\n","    p0 = inputs\n","    s1, p1 = encoder_block(p0, 32, 4)\n","    s2, p2 = encoder_block(p1, 64, 3)\n","    s3, p3 = encoder_block(p2, 128, 2)\n","    s4, p4 = encoder_block(p3, 256, 1)\n","\n","    \"\"\" Bridge \"\"\"\n","    b1 = multires_block(p4, 512)\n","\n","    \"\"\" Decoder \"\"\"\n","    d1 = decoder_block(b1, s4, 256)\n","    d2 = decoder_block(d1, s3, 128)\n","    d3 = decoder_block(d2, s2, 64)\n","    d4 = decoder_block(d3, s1, 32)\n","\n","    \"\"\" Output \"\"\"\n","    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n","\n","    \"\"\" Model \"\"\"\n","    model = Model(inputs, outputs, name=\"MultiResUNET\")\n","\n","    return model\n","\n","if __name__ == \"__main__\":\n","    shape = (256, 256, 3)\n","    model = build_multiresunet(shape)\n","    model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMdrNDqhRYpc","executionInfo":{"status":"ok","timestamp":1689441405423,"user_tz":-330,"elapsed":12524,"user":{"displayName":"VANGA KANISHKA NADH","userId":"15191267719021947787"}},"outputId":"cdfedf07-c8da-488c-a129-fc3a1c168872"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"MultiResUNET\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 256, 256, 8)  216         ['input_1[0][0]']                \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 256, 256, 8)  32         ['conv2d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," activation (Activation)        (None, 256, 256, 8)  0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 256, 256, 17  1224        ['activation[0][0]']             \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 256, 256, 17  68         ['conv2d_1[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_1 (Activation)      (None, 256, 256, 17  0           ['batch_normalization_1[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 256, 256, 26  3978        ['activation_1[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 256, 256, 26  104        ['conv2d_2[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_2 (Activation)      (None, 256, 256, 26  0           ['batch_normalization_2[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 256, 256, 51  0           ['activation[0][0]',             \n","                                )                                 'activation_1[0][0]',           \n","                                                                  'activation_2[0][0]']           \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 256, 256, 51  153         ['input_1[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 256, 256, 51  204        ['concatenate[0][0]']            \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 256, 256, 51  204        ['conv2d_3[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," tf.__operators__.add (TFOpLamb  (None, 256, 256, 51  0          ['batch_normalization_3[0][0]',  \n"," da)                            )                                 'batch_normalization_4[0][0]']  \n","                                                                                                  \n"," activation_3 (Activation)      (None, 256, 256, 51  0           ['tf.__operators__.add[0][0]']   \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 256, 256, 51  204        ['activation_3[0][0]']           \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 128, 128, 51  0           ['batch_normalization_5[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 128, 128, 17  7803        ['max_pooling2d[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 128, 128, 17  68         ['conv2d_12[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_8 (Activation)      (None, 128, 128, 17  0           ['batch_normalization_18[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 128, 128, 35  5355        ['activation_8[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 128, 128, 35  140        ['conv2d_13[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_9 (Activation)      (None, 128, 128, 35  0           ['batch_normalization_19[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 128, 128, 53  16695       ['activation_9[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 128, 128, 53  212        ['conv2d_14[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_10 (Activation)     (None, 128, 128, 53  0           ['batch_normalization_20[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 128, 128, 10  0           ['activation_8[0][0]',           \n","                                5)                                'activation_9[0][0]',           \n","                                                                  'activation_10[0][0]']          \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 128, 128, 10  5355        ['max_pooling2d[0][0]']          \n","                                5)                                                                \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 128, 128, 10  420        ['concatenate_1[0][0]']          \n"," ormalization)                  5)                                                                \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 128, 128, 10  420        ['conv2d_15[0][0]']              \n"," ormalization)                  5)                                                                \n","                                                                                                  \n"," tf.__operators__.add_5 (TFOpLa  (None, 128, 128, 10  0          ['batch_normalization_21[0][0]', \n"," mbda)                          5)                                'batch_normalization_22[0][0]'] \n","                                                                                                  \n"," activation_11 (Activation)     (None, 128, 128, 10  0           ['tf.__operators__.add_5[0][0]'] \n","                                5)                                                                \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 128, 128, 10  420        ['activation_11[0][0]']          \n"," ormalization)                  5)                                                                \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 105)  0          ['batch_normalization_23[0][0]'] \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 64, 64, 35)   33075       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 64, 64, 35)  140         ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_15 (Activation)     (None, 64, 64, 35)   0           ['batch_normalization_33[0][0]'] \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 64, 64, 71)   22365       ['activation_15[0][0]']          \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 64, 64, 71)  284         ['conv2d_23[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_16 (Activation)     (None, 64, 64, 71)   0           ['batch_normalization_34[0][0]'] \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 64, 64, 106)  67734       ['activation_16[0][0]']          \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 64, 64, 106)  424        ['conv2d_24[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_17 (Activation)     (None, 64, 64, 106)  0           ['batch_normalization_35[0][0]'] \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 64, 64, 212)  0           ['activation_15[0][0]',          \n","                                                                  'activation_16[0][0]',          \n","                                                                  'activation_17[0][0]']          \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 64, 64, 212)  22260       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," batch_normalization_36 (BatchN  (None, 64, 64, 212)  848        ['concatenate_2[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_37 (BatchN  (None, 64, 64, 212)  848        ['conv2d_25[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_9 (TFOpLa  (None, 64, 64, 212)  0          ['batch_normalization_36[0][0]', \n"," mbda)                                                            'batch_normalization_37[0][0]'] \n","                                                                                                  \n"," activation_18 (Activation)     (None, 64, 64, 212)  0           ['tf.__operators__.add_9[0][0]'] \n","                                                                                                  \n"," batch_normalization_38 (BatchN  (None, 64, 64, 212)  848        ['activation_18[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 212)  0          ['batch_normalization_38[0][0]'] \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 32, 32, 71)   135468      ['max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," batch_normalization_45 (BatchN  (None, 32, 32, 71)  284         ['conv2d_30[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_21 (Activation)     (None, 32, 32, 71)   0           ['batch_normalization_45[0][0]'] \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 32, 32, 142)  90738       ['activation_21[0][0]']          \n","                                                                                                  \n"," batch_normalization_46 (BatchN  (None, 32, 32, 142)  568        ['conv2d_31[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_22 (Activation)     (None, 32, 32, 142)  0           ['batch_normalization_46[0][0]'] \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 32, 32, 213)  272214      ['activation_22[0][0]']          \n","                                                                                                  \n"," batch_normalization_47 (BatchN  (None, 32, 32, 213)  852        ['conv2d_32[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_23 (Activation)     (None, 32, 32, 213)  0           ['batch_normalization_47[0][0]'] \n","                                                                                                  \n"," concatenate_3 (Concatenate)    (None, 32, 32, 426)  0           ['activation_21[0][0]',          \n","                                                                  'activation_22[0][0]',          \n","                                                                  'activation_23[0][0]']          \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 32, 32, 426)  90312       ['max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," batch_normalization_48 (BatchN  (None, 32, 32, 426)  1704       ['concatenate_3[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_49 (BatchN  (None, 32, 32, 426)  1704       ['conv2d_33[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_12 (TFOpL  (None, 32, 32, 426)  0          ['batch_normalization_48[0][0]', \n"," ambda)                                                           'batch_normalization_49[0][0]'] \n","                                                                                                  \n"," activation_24 (Activation)     (None, 32, 32, 426)  0           ['tf.__operators__.add_12[0][0]']\n","                                                                                                  \n"," batch_normalization_50 (BatchN  (None, 32, 32, 426)  1704       ['activation_24[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 426)  0          ['batch_normalization_50[0][0]'] \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 16, 16, 142)  544428      ['max_pooling2d_3[0][0]']        \n","                                                                                                  \n"," batch_normalization_54 (BatchN  (None, 16, 16, 142)  568        ['conv2d_36[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_26 (Activation)     (None, 16, 16, 142)  0           ['batch_normalization_54[0][0]'] \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 16, 16, 284)  362952      ['activation_26[0][0]']          \n","                                                                                                  \n"," batch_normalization_55 (BatchN  (None, 16, 16, 284)  1136       ['conv2d_37[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_27 (Activation)     (None, 16, 16, 284)  0           ['batch_normalization_55[0][0]'] \n","                                                                                                  \n"," conv2d_38 (Conv2D)             (None, 16, 16, 427)  1091412     ['activation_27[0][0]']          \n","                                                                                                  \n"," batch_normalization_56 (BatchN  (None, 16, 16, 427)  1708       ['conv2d_38[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_28 (Activation)     (None, 16, 16, 427)  0           ['batch_normalization_56[0][0]'] \n","                                                                                                  \n"," concatenate_4 (Concatenate)    (None, 16, 16, 853)  0           ['activation_26[0][0]',          \n","                                                                  'activation_27[0][0]',          \n","                                                                  'activation_28[0][0]']          \n","                                                                                                  \n"," conv2d_39 (Conv2D)             (None, 16, 16, 853)  363378      ['max_pooling2d_3[0][0]']        \n","                                                                                                  \n"," batch_normalization_57 (BatchN  (None, 16, 16, 853)  3412       ['concatenate_4[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_58 (BatchN  (None, 16, 16, 853)  3412       ['conv2d_39[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 32, 32, 256)  981504      ['batch_normalization_50[0][0]'] \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 32, 32, 256)  109056      ['batch_normalization_50[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_14 (TFOpL  (None, 16, 16, 853)  0          ['batch_normalization_57[0][0]', \n"," ambda)                                                           'batch_normalization_58[0][0]'] \n","                                                                                                  \n"," batch_normalization_51 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_34[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_52 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_35[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_29 (Activation)     (None, 16, 16, 853)  0           ['tf.__operators__.add_14[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_13 (TFOpL  (None, 32, 32, 256)  0          ['batch_normalization_51[0][0]', \n"," ambda)                                                           'batch_normalization_52[0][0]'] \n","                                                                                                  \n"," batch_normalization_59 (BatchN  (None, 16, 16, 853)  3412       ['activation_29[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_25 (Activation)     (None, 32, 32, 256)  0           ['tf.__operators__.add_13[0][0]']\n","                                                                                                  \n"," conv2d_transpose (Conv2DTransp  (None, 32, 32, 256)  873728     ['batch_normalization_59[0][0]'] \n"," ose)                                                                                             \n","                                                                                                  \n"," batch_normalization_53 (BatchN  (None, 32, 32, 256)  1024       ['activation_25[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," concatenate_5 (Concatenate)    (None, 32, 32, 512)  0           ['conv2d_transpose[0][0]',       \n","                                                                  'batch_normalization_53[0][0]'] \n","                                                                                                  \n"," conv2d_40 (Conv2D)             (None, 32, 32, 71)   327168      ['concatenate_5[0][0]']          \n","                                                                                                  \n"," batch_normalization_60 (BatchN  (None, 32, 32, 71)  284         ['conv2d_40[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_30 (Activation)     (None, 32, 32, 71)   0           ['batch_normalization_60[0][0]'] \n","                                                                                                  \n"," conv2d_41 (Conv2D)             (None, 32, 32, 142)  90738       ['activation_30[0][0]']          \n","                                                                                                  \n"," batch_normalization_61 (BatchN  (None, 32, 32, 142)  568        ['conv2d_41[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_31 (Activation)     (None, 32, 32, 142)  0           ['batch_normalization_61[0][0]'] \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 64, 64, 128)  244224      ['batch_normalization_38[0][0]'] \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 64, 64, 128)  27136       ['batch_normalization_38[0][0]'] \n","                                                                                                  \n"," conv2d_42 (Conv2D)             (None, 32, 32, 213)  272214      ['activation_31[0][0]']          \n","                                                                                                  \n"," batch_normalization_39 (BatchN  (None, 64, 64, 128)  512        ['conv2d_26[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_40 (BatchN  (None, 64, 64, 128)  512        ['conv2d_27[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_62 (BatchN  (None, 32, 32, 213)  852        ['conv2d_42[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_10 (TFOpL  (None, 64, 64, 128)  0          ['batch_normalization_39[0][0]', \n"," ambda)                                                           'batch_normalization_40[0][0]'] \n","                                                                                                  \n"," activation_32 (Activation)     (None, 32, 32, 213)  0           ['batch_normalization_62[0][0]'] \n","                                                                                                  \n"," activation_19 (Activation)     (None, 64, 64, 128)  0           ['tf.__operators__.add_10[0][0]']\n","                                                                                                  \n"," concatenate_6 (Concatenate)    (None, 32, 32, 426)  0           ['activation_30[0][0]',          \n","                                                                  'activation_31[0][0]',          \n","                                                                  'activation_32[0][0]']          \n","                                                                                                  \n"," conv2d_43 (Conv2D)             (None, 32, 32, 426)  218112      ['concatenate_5[0][0]']          \n","                                                                                                  \n"," batch_normalization_41 (BatchN  (None, 64, 64, 128)  512        ['activation_19[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_63 (BatchN  (None, 32, 32, 426)  1704       ['concatenate_6[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_64 (BatchN  (None, 32, 32, 426)  1704       ['conv2d_43[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 64, 64, 128)  147456      ['batch_normalization_41[0][0]'] \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 64, 64, 128)  16384       ['batch_normalization_41[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_15 (TFOpL  (None, 32, 32, 426)  0          ['batch_normalization_63[0][0]', \n"," ambda)                                                           'batch_normalization_64[0][0]'] \n","                                                                                                  \n"," batch_normalization_42 (BatchN  (None, 64, 64, 128)  512        ['conv2d_28[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_43 (BatchN  (None, 64, 64, 128)  512        ['conv2d_29[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_33 (Activation)     (None, 32, 32, 426)  0           ['tf.__operators__.add_15[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_11 (TFOpL  (None, 64, 64, 128)  0          ['batch_normalization_42[0][0]', \n"," ambda)                                                           'batch_normalization_43[0][0]'] \n","                                                                                                  \n"," batch_normalization_65 (BatchN  (None, 32, 32, 426)  1704       ['activation_33[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_20 (Activation)     (None, 64, 64, 128)  0           ['tf.__operators__.add_11[0][0]']\n","                                                                                                  \n"," conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 128)  218240     ['batch_normalization_65[0][0]'] \n"," spose)                                                                                           \n","                                                                                                  \n"," batch_normalization_44 (BatchN  (None, 64, 64, 128)  512        ['activation_20[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," concatenate_7 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_transpose_1[0][0]',     \n","                                                                  'batch_normalization_44[0][0]'] \n","                                                                                                  \n"," conv2d_44 (Conv2D)             (None, 64, 64, 35)   80640       ['concatenate_7[0][0]']          \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 128, 128, 64  60480       ['batch_normalization_23[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 128, 128, 64  6720        ['batch_normalization_23[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_66 (BatchN  (None, 64, 64, 35)  140         ['conv2d_44[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 128, 128, 64  256        ['conv2d_16[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 128, 128, 64  256        ['conv2d_17[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_34 (Activation)     (None, 64, 64, 35)   0           ['batch_normalization_66[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_6 (TFOpLa  (None, 128, 128, 64  0          ['batch_normalization_24[0][0]', \n"," mbda)                          )                                 'batch_normalization_25[0][0]'] \n","                                                                                                  \n"," conv2d_45 (Conv2D)             (None, 64, 64, 71)   22365       ['activation_34[0][0]']          \n","                                                                                                  \n"," activation_12 (Activation)     (None, 128, 128, 64  0           ['tf.__operators__.add_6[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_67 (BatchN  (None, 64, 64, 71)  284         ['conv2d_45[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 128, 128, 64  256        ['activation_12[0][0]']          \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_35 (Activation)     (None, 64, 64, 71)   0           ['batch_normalization_67[0][0]'] \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 128, 128, 64  36864       ['batch_normalization_26[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 128, 128, 64  4096        ['batch_normalization_26[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_46 (Conv2D)             (None, 64, 64, 106)  67734       ['activation_35[0][0]']          \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 128, 128, 64  256        ['conv2d_18[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 128, 128, 64  256        ['conv2d_19[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_68 (BatchN  (None, 64, 64, 106)  424        ['conv2d_46[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_7 (TFOpLa  (None, 128, 128, 64  0          ['batch_normalization_27[0][0]', \n"," mbda)                          )                                 'batch_normalization_28[0][0]'] \n","                                                                                                  \n"," activation_36 (Activation)     (None, 64, 64, 106)  0           ['batch_normalization_68[0][0]'] \n","                                                                                                  \n"," activation_13 (Activation)     (None, 128, 128, 64  0           ['tf.__operators__.add_7[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_8 (Concatenate)    (None, 64, 64, 212)  0           ['activation_34[0][0]',          \n","                                                                  'activation_35[0][0]',          \n","                                                                  'activation_36[0][0]']          \n","                                                                                                  \n"," conv2d_47 (Conv2D)             (None, 64, 64, 212)  54272       ['concatenate_7[0][0]']          \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 128, 128, 64  256        ['activation_13[0][0]']          \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_69 (BatchN  (None, 64, 64, 212)  848        ['concatenate_8[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_70 (BatchN  (None, 64, 64, 212)  848        ['conv2d_47[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 128, 128, 64  36864       ['batch_normalization_29[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 128, 128, 64  4096        ['batch_normalization_29[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," tf.__operators__.add_16 (TFOpL  (None, 64, 64, 212)  0          ['batch_normalization_69[0][0]', \n"," ambda)                                                           'batch_normalization_70[0][0]'] \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 128, 128, 64  256        ['conv2d_20[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 128, 128, 64  256        ['conv2d_21[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 256, 256, 32  14688       ['batch_normalization_5[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 256, 256, 32  1632        ['batch_normalization_5[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," activation_37 (Activation)     (None, 64, 64, 212)  0           ['tf.__operators__.add_16[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_8 (TFOpLa  (None, 128, 128, 64  0          ['batch_normalization_30[0][0]', \n"," mbda)                          )                                 'batch_normalization_31[0][0]'] \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 256, 256, 32  128        ['conv2d_4[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 256, 256, 32  128        ['conv2d_5[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," batch_normalization_71 (BatchN  (None, 64, 64, 212)  848        ['activation_37[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_14 (Activation)     (None, 128, 128, 64  0           ['tf.__operators__.add_8[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," tf.__operators__.add_1 (TFOpLa  (None, 256, 256, 32  0          ['batch_normalization_6[0][0]',  \n"," mbda)                          )                                 'batch_normalization_7[0][0]']  \n","                                                                                                  \n"," conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 64  54336      ['batch_normalization_71[0][0]'] \n"," spose)                         )                                                                 \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 128, 128, 64  256        ['activation_14[0][0]']          \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_4 (Activation)      (None, 256, 256, 32  0           ['tf.__operators__.add_1[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_9 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_transpose_2[0][0]',     \n","                                8)                                'batch_normalization_32[0][0]'] \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 256, 256, 32  128        ['activation_4[0][0]']           \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," conv2d_48 (Conv2D)             (None, 128, 128, 17  19584       ['concatenate_9[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 256, 256, 32  9216        ['batch_normalization_8[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 256, 256, 32  1024        ['batch_normalization_8[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_72 (BatchN  (None, 128, 128, 17  68         ['conv2d_48[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 256, 256, 32  128        ['conv2d_6[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 256, 256, 32  128        ['conv2d_7[0][0]']               \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_38 (Activation)     (None, 128, 128, 17  0           ['batch_normalization_72[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," tf.__operators__.add_2 (TFOpLa  (None, 256, 256, 32  0          ['batch_normalization_9[0][0]',  \n"," mbda)                          )                                 'batch_normalization_10[0][0]'] \n","                                                                                                  \n"," conv2d_49 (Conv2D)             (None, 128, 128, 35  5355        ['activation_38[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," activation_5 (Activation)      (None, 256, 256, 32  0           ['tf.__operators__.add_2[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_73 (BatchN  (None, 128, 128, 35  140        ['conv2d_49[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 256, 256, 32  128        ['activation_5[0][0]']           \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_39 (Activation)     (None, 128, 128, 35  0           ['batch_normalization_73[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 256, 256, 32  9216        ['batch_normalization_11[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 256, 256, 32  1024        ['batch_normalization_11[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_50 (Conv2D)             (None, 128, 128, 53  16695       ['activation_39[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 256, 256, 32  128        ['conv2d_8[0][0]']               \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 256, 256, 32  128        ['conv2d_9[0][0]']               \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_74 (BatchN  (None, 128, 128, 53  212        ['conv2d_50[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," tf.__operators__.add_3 (TFOpLa  (None, 256, 256, 32  0          ['batch_normalization_12[0][0]', \n"," mbda)                          )                                 'batch_normalization_13[0][0]'] \n","                                                                                                  \n"," activation_40 (Activation)     (None, 128, 128, 53  0           ['batch_normalization_74[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," activation_6 (Activation)      (None, 256, 256, 32  0           ['tf.__operators__.add_3[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_10 (Concatenate)   (None, 128, 128, 10  0           ['activation_38[0][0]',          \n","                                5)                                'activation_39[0][0]',          \n","                                                                  'activation_40[0][0]']          \n","                                                                                                  \n"," conv2d_51 (Conv2D)             (None, 128, 128, 10  13440       ['concatenate_9[0][0]']          \n","                                5)                                                                \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 256, 256, 32  128        ['activation_6[0][0]']           \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_75 (BatchN  (None, 128, 128, 10  420        ['concatenate_10[0][0]']         \n"," ormalization)                  5)                                                                \n","                                                                                                  \n"," batch_normalization_76 (BatchN  (None, 128, 128, 10  420        ['conv2d_51[0][0]']              \n"," ormalization)                  5)                                                                \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 256, 256, 32  9216        ['batch_normalization_14[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 256, 256, 32  1024        ['batch_normalization_14[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," tf.__operators__.add_17 (TFOpL  (None, 128, 128, 10  0          ['batch_normalization_75[0][0]', \n"," ambda)                         5)                                'batch_normalization_76[0][0]'] \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 256, 256, 32  128        ['conv2d_10[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 256, 256, 32  128        ['conv2d_11[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_41 (Activation)     (None, 128, 128, 10  0           ['tf.__operators__.add_17[0][0]']\n","                                5)                                                                \n","                                                                                                  \n"," tf.__operators__.add_4 (TFOpLa  (None, 256, 256, 32  0          ['batch_normalization_15[0][0]', \n"," mbda)                          )                                 'batch_normalization_16[0][0]'] \n","                                                                                                  \n"," batch_normalization_77 (BatchN  (None, 128, 128, 10  420        ['activation_41[0][0]']          \n"," ormalization)                  5)                                                                \n","                                                                                                  \n"," activation_7 (Activation)      (None, 256, 256, 32  0           ['tf.__operators__.add_4[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 32  13472      ['batch_normalization_77[0][0]'] \n"," spose)                         )                                                                 \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 256, 256, 32  128        ['activation_7[0][0]']           \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," concatenate_11 (Concatenate)   (None, 256, 256, 64  0           ['conv2d_transpose_3[0][0]',     \n","                                )                                 'batch_normalization_17[0][0]'] \n","                                                                                                  \n"," conv2d_52 (Conv2D)             (None, 256, 256, 8)  4608        ['concatenate_11[0][0]']         \n","                                                                                                  \n"," batch_normalization_78 (BatchN  (None, 256, 256, 8)  32         ['conv2d_52[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_42 (Activation)     (None, 256, 256, 8)  0           ['batch_normalization_78[0][0]'] \n","                                                                                                  \n"," conv2d_53 (Conv2D)             (None, 256, 256, 17  1224        ['activation_42[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_79 (BatchN  (None, 256, 256, 17  68         ['conv2d_53[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_43 (Activation)     (None, 256, 256, 17  0           ['batch_normalization_79[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_54 (Conv2D)             (None, 256, 256, 26  3978        ['activation_43[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_80 (BatchN  (None, 256, 256, 26  104        ['conv2d_54[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_44 (Activation)     (None, 256, 256, 26  0           ['batch_normalization_80[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_12 (Concatenate)   (None, 256, 256, 51  0           ['activation_42[0][0]',          \n","                                )                                 'activation_43[0][0]',          \n","                                                                  'activation_44[0][0]']          \n","                                                                                                  \n"," conv2d_55 (Conv2D)             (None, 256, 256, 51  3264        ['concatenate_11[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_81 (BatchN  (None, 256, 256, 51  204        ['concatenate_12[0][0]']         \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_82 (BatchN  (None, 256, 256, 51  204        ['conv2d_55[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," tf.__operators__.add_18 (TFOpL  (None, 256, 256, 51  0          ['batch_normalization_81[0][0]', \n"," ambda)                         )                                 'batch_normalization_82[0][0]'] \n","                                                                                                  \n"," activation_45 (Activation)     (None, 256, 256, 51  0           ['tf.__operators__.add_18[0][0]']\n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_83 (BatchN  (None, 256, 256, 51  204        ['activation_45[0][0]']          \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," conv2d_56 (Conv2D)             (None, 256, 256, 1)  52          ['batch_normalization_83[0][0]'] \n","                                                                                                  \n","==================================================================================================\n","Total params: 7,269,294\n","Trainable params: 7,244,774\n","Non-trainable params: 24,520\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","\n","def iou(y_true, y_pred):\n","    def f(y_true, y_pred):\n","        intersection = (y_true * y_pred).sum()\n","        union = y_true.sum() + y_pred.sum() - intersection\n","        x = (intersection + 1e-15) / (union + 1e-15)\n","        x = x.astype(np.float32)\n","        return x\n","    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n","\n","smooth = 1e-15\n","def dice_coef(y_true, y_pred):\n","    y_true = tf.keras.layers.Flatten()(y_true)\n","    y_pred = tf.keras.layers.Flatten()(y_pred)\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n","\n","def dice_loss(y_true, y_pred):\n","    return 1.0 - dice_coef(y_true, y_pred)"],"metadata":{"id":"4heYTkJ_ReIy","executionInfo":{"status":"ok","timestamp":1689441405425,"user_tz":-330,"elapsed":115,"user":{"displayName":"VANGA KANISHKA NADH","userId":"15191267719021947787"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","import numpy as np\n","import cv2\n","from glob import glob\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import Recall, Precision\n","\n","\n","H = 256\n","W = 256\n","\n","def create_dir(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","def shuffling(x, y):\n","    x, y = shuffle(x, y, random_state=42)\n","\n","def read_image(path):\n","    path = path.decode()\n","    x = cv2.imread(path, cv2.IMREAD_COLOR)\n","    x = cv2.resize(x, (W, H))\n","    x = x/255.0\n","    x = x.astype(np.float32)\n","    return x\n","\n","def read_mask(path):\n","    path = path.decode()\n","    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","    x = cv2.resize(x, (W, H))\n","    x = x/255.0\n","    x = x.astype(np.float32)\n","    x = np.expand_dims(x, axis=-1)\n","    return x\n","\n","def tf_parse(x, y):\n","    def _parse(x, y):\n","        x = read_image(x)\n","        y = read_mask(y)\n","        return x, y\n","\n","    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n","    x.set_shape([H, W, 3])\n","    y.set_shape([H, W, 1])\n","    return x, y\n","\n","def tf_dataset(X, Y, batch=8):\n","    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n","    dataset = dataset.map(tf_parse)\n","    dataset = dataset.batch(batch)\n","    dataset = dataset.prefetch(10)\n","    return dataset\n","\n","def load_data(path, split=0.2):\n","    images = sorted(glob(os.path.join(path, \"images\", \"*.jpg\")))\n","    masks = sorted(glob(os.path.join(path, \"masks\", \"*.jpg\")))\n","    size = int(len(images) * split)\n","\n","    train_x, valid_x = train_test_split(images, test_size=size, random_state=42)\n","    train_y, valid_y = train_test_split(masks, test_size=size, random_state=42)\n","\n","    train_x, test_x = train_test_split(train_x, test_size=size, random_state=42)\n","    train_y, test_y = train_test_split(train_y, test_size=size, random_state=42)\n","\n","    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n","\n","\n","\n","\n","if __name__ == \"__main__\":\n","    \"\"\" Seeding \"\"\"\n","    np.random.seed(42)\n","    tf.random.set_seed(42)\n","\n","    \"\"\" Directory to save files \"\"\"\n","    create_dir(\"files\")\n","\n","    \"\"\" Hyperparaqmeters \"\"\"\n","    batch_size = 8\n","    lr = 1e-4   ## 0.0001\n","    num_epochs = 10\n","    model_path = \"files/model.h5\"\n","    csv_path = \"files/data.csv\"\n","\n","    \"\"\" Dataset \"\"\"\n","    dataset_path = \"/content/drive/MyDrive/CELL (1)/DSB/\"\n","    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(dataset_path)\n","    train_x, train_y = shuffle(train_x, train_y)\n","\n","    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n","    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n","    print(f\"Test: {len(test_x)} - {len(test_y)}\")\n","\n","    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n","    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n","\n","    # ds = (1, 2, 3, 4, 5)\n","    # bs = 2\n","    # n = len(ds)//bs = 2\n","    # [1, 2], [3, 4], [1]\n","\n","    train_steps = (len(train_x)//batch_size)\n","    valid_steps = (len(valid_x)//batch_size)\n","\n","    if len(train_x) % batch_size != 0:\n","        train_steps += 1\n","\n","    if len(valid_x) % batch_size != 0:\n","        valid_steps += 1\n","\n","    \"\"\" Model \"\"\"\n","    model = build_multiresunet(shape)\n","    metrics = [dice_coef, iou, Recall(), Precision()]\n","    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr), metrics=metrics)\n","\n","    callbacks = [\n","        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n","        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n","        CSVLogger(csv_path),\n","        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n","    ]\n","\n","    model.fit(\n","        train_dataset,\n","        epochs=num_epochs,\n","        validation_data=valid_dataset,\n","        steps_per_epoch=train_steps,\n","        validation_steps=valid_steps,\n","        callbacks=callbacks\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7staluI-RhEw","executionInfo":{"status":"ok","timestamp":1689441885602,"user_tz":-330,"elapsed":480288,"user":{"displayName":"VANGA KANISHKA NADH","userId":"15191267719021947787"}},"outputId":"48eb73de-8248-44bb-e3d2-305f9b88b3eb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Train: 402 - 402\n","Valid: 134 - 134\n","Test: 134 - 134\n","Epoch 1/10\n","51/51 [==============================] - ETA: 0s - loss: 0.6011 - dice_coef: 0.3602 - iou: 0.2229 - recall: 0.7422 - precision: 0.4443\n","Epoch 1: val_loss improved from inf to 0.62193, saving model to files/model.h5\n","51/51 [==============================] - 208s 3s/step - loss: 0.6011 - dice_coef: 0.3602 - iou: 0.2229 - recall: 0.7422 - precision: 0.4443 - val_loss: 0.6219 - val_dice_coef: 0.1854 - val_iou: 0.1028 - val_recall: 2.5215e-04 - val_precision: 0.0189 - lr: 1.0000e-04\n","Epoch 2/10\n","51/51 [==============================] - ETA: 0s - loss: 0.4056 - dice_coef: 0.4603 - iou: 0.3044 - recall: 0.7504 - precision: 0.6772\n","Epoch 2: val_loss improved from 0.62193 to 0.54406, saving model to files/model.h5\n","51/51 [==============================] - 25s 496ms/step - loss: 0.4056 - dice_coef: 0.4603 - iou: 0.3044 - recall: 0.7504 - precision: 0.6772 - val_loss: 0.5441 - val_dice_coef: 0.1777 - val_iou: 0.0980 - val_recall: 1.4870e-05 - val_precision: 0.7188 - lr: 1.0000e-04\n","Epoch 3/10\n","51/51 [==============================] - ETA: 0s - loss: 0.2884 - dice_coef: 0.5338 - iou: 0.3719 - recall: 0.7060 - precision: 0.8324\n","Epoch 3: val_loss improved from 0.54406 to 0.49610, saving model to files/model.h5\n","51/51 [==============================] - 25s 491ms/step - loss: 0.2884 - dice_coef: 0.5338 - iou: 0.3719 - recall: 0.7060 - precision: 0.8324 - val_loss: 0.4961 - val_dice_coef: 0.1677 - val_iou: 0.0919 - val_recall: 9.3748e-05 - val_precision: 0.5556 - lr: 1.0000e-04\n","Epoch 4/10\n","51/51 [==============================] - ETA: 0s - loss: 0.2350 - dice_coef: 0.5819 - iou: 0.4197 - recall: 0.6828 - precision: 0.8873\n","Epoch 4: val_loss improved from 0.49610 to 0.45129, saving model to files/model.h5\n","51/51 [==============================] - 26s 502ms/step - loss: 0.2350 - dice_coef: 0.5819 - iou: 0.4197 - recall: 0.6828 - precision: 0.8873 - val_loss: 0.4513 - val_dice_coef: 0.1632 - val_iou: 0.0892 - val_recall: 0.0025 - val_precision: 0.6335 - lr: 1.0000e-04\n","Epoch 5/10\n","51/51 [==============================] - ETA: 0s - loss: 0.2021 - dice_coef: 0.6157 - iou: 0.4552 - recall: 0.6743 - precision: 0.9135\n","Epoch 5: val_loss improved from 0.45129 to 0.41772, saving model to files/model.h5\n","51/51 [==============================] - 25s 485ms/step - loss: 0.2021 - dice_coef: 0.6157 - iou: 0.4552 - recall: 0.6743 - precision: 0.9135 - val_loss: 0.4177 - val_dice_coef: 0.2127 - val_iou: 0.1197 - val_recall: 0.1078 - val_precision: 0.6105 - lr: 1.0000e-04\n","Epoch 6/10\n","51/51 [==============================] - ETA: 0s - loss: 0.1788 - dice_coef: 0.6438 - iou: 0.4861 - recall: 0.6724 - precision: 0.9288\n","Epoch 6: val_loss improved from 0.41772 to 0.36740, saving model to files/model.h5\n","51/51 [==============================] - 26s 504ms/step - loss: 0.1788 - dice_coef: 0.6438 - iou: 0.4861 - recall: 0.6724 - precision: 0.9288 - val_loss: 0.3674 - val_dice_coef: 0.2975 - val_iou: 0.1762 - val_recall: 0.3142 - val_precision: 0.7705 - lr: 1.0000e-04\n","Epoch 7/10\n","51/51 [==============================] - ETA: 0s - loss: 0.1612 - dice_coef: 0.6662 - iou: 0.5115 - recall: 0.6714 - precision: 0.9387\n","Epoch 7: val_loss improved from 0.36740 to 0.32665, saving model to files/model.h5\n","51/51 [==============================] - 25s 495ms/step - loss: 0.1612 - dice_coef: 0.6662 - iou: 0.5115 - recall: 0.6714 - precision: 0.9387 - val_loss: 0.3267 - val_dice_coef: 0.4146 - val_iou: 0.2638 - val_recall: 0.4869 - val_precision: 0.7666 - lr: 1.0000e-04\n","Epoch 8/10\n","51/51 [==============================] - ETA: 0s - loss: 0.1493 - dice_coef: 0.6833 - iou: 0.5313 - recall: 0.6710 - precision: 0.9456\n","Epoch 8: val_loss improved from 0.32665 to 0.32086, saving model to files/model.h5\n","51/51 [==============================] - 26s 505ms/step - loss: 0.1493 - dice_coef: 0.6833 - iou: 0.5313 - recall: 0.6710 - precision: 0.9456 - val_loss: 0.3209 - val_dice_coef: 0.4805 - val_iou: 0.3188 - val_recall: 0.5498 - val_precision: 0.7759 - lr: 1.0000e-04\n","Epoch 9/10\n","51/51 [==============================] - ETA: 0s - loss: 0.1385 - dice_coef: 0.6989 - iou: 0.5499 - recall: 0.6703 - precision: 0.9514\n","Epoch 9: val_loss did not improve from 0.32086\n","51/51 [==============================] - 25s 484ms/step - loss: 0.1385 - dice_coef: 0.6989 - iou: 0.5499 - recall: 0.6703 - precision: 0.9514 - val_loss: 0.3551 - val_dice_coef: 0.5605 - val_iou: 0.3915 - val_recall: 0.6567 - val_precision: 0.7804 - lr: 1.0000e-04\n","Epoch 10/10\n","51/51 [==============================] - ETA: 0s - loss: 0.1262 - dice_coef: 0.7178 - iou: 0.5732 - recall: 0.6755 - precision: 0.9573\n","Epoch 10: val_loss improved from 0.32086 to 0.26643, saving model to files/model.h5\n","51/51 [==============================] - 25s 497ms/step - loss: 0.1262 - dice_coef: 0.7178 - iou: 0.5732 - recall: 0.6755 - precision: 0.9573 - val_loss: 0.2664 - val_dice_coef: 0.6274 - val_iou: 0.4597 - val_recall: 0.6805 - val_precision: 0.8470 - lr: 1.0000e-04\n"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","import numpy as np\n","import cv2\n","import pandas as pd\n","from glob import glob\n","from tqdm import tqdm\n","import tensorflow as tf\n","from tensorflow.keras.utils import CustomObjectScope\n","from sklearn.metrics import accuracy_score,f1_score,jaccard_score,recall_score,precision_score\n","\n","\n","H = 256\n","W = 256\n","\n","def create_dir(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","def read_image(path):\n","    x = cv2.imread(path, cv2.IMREAD_COLOR)\n","    x = cv2.resize(x, (W, H))\n","    ori_x = x\n","    x = x/255.0\n","    x = x.astype(np.float32)\n","    x = np.expand_dims(x, axis=0)   ## (1, 256, 256, 3)\n","    return ori_x, x\n","\n","def read_mask(path):\n","    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","    x = cv2.resize(x, (W, H))\n","    ori_x = x\n","    x = x/255.0\n","    x = x > 0.5\n","    x = x.astype(np.int32)\n","    return ori_x, x\n","\n","def save_result(ori_x, ori_y, y_pred, save_path):\n","    line = np.ones((H, 10, 3)) * 255\n","\n","    ori_y = np.expand_dims(ori_y, axis=-1) ## (256, 256, 1)\n","    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1) ## (256, 256, 3)\n","\n","    y_pred = np.expand_dims(y_pred, axis=-1)\n","    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1) * 255.0\n","\n","    cat_images = np.concatenate([ori_x, line, ori_y, line, y_pred], axis=1)\n","    cv2.imwrite(save_path, cat_images)\n","\n","if __name__ == \"__main__\":\n","    create_dir(\"results\")\n","\n","    \"\"\" Load Model \"\"\"\n","    with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n","        model = tf.keras.models.load_model(\"files/model.h5\")\n","\n","    \"\"\" Dataset \"\"\"\n","    path= \"/content/drive/MyDrive/CELL (1)/DSB/\"\n","    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n","\n","    \"\"\" Prediction and metrics values \"\"\"\n","    SCORE = []\n","    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n","        name = x.split(\"/\")[-1]\n","\n","        \"\"\" Reading the image and mask \"\"\"\n","        ori_x, x = read_image(x)\n","        ori_y, y = read_mask(y)\n","\n","        \"\"\" Prediction \"\"\"\n","        y_pred = model.predict(x)[0] > 0.5\n","        y_pred = np.squeeze(y_pred, axis=-1)\n","        y_pred = y_pred.astype(np.int32)\n","\n","        save_path = f\"results/{name}\"\n","        save_result(ori_x, ori_y, y_pred, save_path)\n","\n","        \"\"\" Flattening the numpy arrays. \"\"\"\n","        y = y.flatten()\n","        y_pred = y_pred.flatten()\n","\n","        \"\"\" Calculating metrics values \"\"\"\n","        acc_value = accuracy_score(y, y_pred)\n","        f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n","        jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n","        recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n","        precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n","        SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n","\n","    \"\"\" Metrics values \"\"\"\n","    score = [s[1:]for s in SCORE]\n","    score = np.mean(score, axis=0)\n","    print(f\"Accuracy: {score[0]:0.5f}\")\n","    print(f\"F1: {score[1]:0.5f}\")\n","    print(f\"Jaccard: {score[2]:0.5f}\")\n","    print(f\"Recall: {score[3]:0.5f}\")\n","    print(f\"Precision: {score[4]:0.5f}\")\n","\n","    \"\"\" Saving all the results \"\"\"\n","    df = pd.DataFrame(SCORE, columns=[\"Image\", \"Accuracy\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n","    df.to_csv(\"files/score.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zATilFzFRzVj","executionInfo":{"status":"ok","timestamp":1689441953844,"user_tz":-330,"elapsed":68267,"user":{"displayName":"VANGA KANISHKA NADH","userId":"15191267719021947787"}},"outputId":"d91e2e9e-391e-49cc-c7ab-b405a170a28b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/134 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 3s 3s/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 1/134 [00:04<08:56,  4.03s/it]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|▏         | 2/134 [00:04<04:06,  1.86s/it]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 3/134 [00:04<02:39,  1.22s/it]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 4/134 [00:05<01:57,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▎         | 5/134 [00:05<01:33,  1.38it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 6/134 [00:06<01:19,  1.62it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 7/134 [00:06<01:13,  1.73it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 8/134 [00:06<01:04,  1.97it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 9/134 [00:07<01:02,  2.00it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 10/134 [00:07<01:03,  1.96it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 37ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 11/134 [00:08<01:02,  1.97it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 38ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▉         | 12/134 [00:09<01:06,  1.83it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 41ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|▉         | 13/134 [00:09<01:05,  1.86it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 39ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 14/134 [00:10<01:06,  1.81it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█         | 15/134 [00:10<01:00,  1.98it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 16/134 [00:11<00:57,  2.04it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 17/134 [00:11<00:59,  1.96it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 18/134 [00:12<01:04,  1.80it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 19/134 [00:12<00:58,  1.96it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▍        | 20/134 [00:13<00:56,  2.01it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 21/134 [00:13<00:54,  2.09it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▋        | 22/134 [00:14<00:57,  1.93it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 23/134 [00:14<00:53,  2.08it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 24/134 [00:14<00:50,  2.18it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▊        | 25/134 [00:15<00:52,  2.08it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 26/134 [00:15<00:49,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 27/134 [00:16<00:49,  2.18it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██        | 28/134 [00:16<00:49,  2.16it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 29/134 [00:17<00:49,  2.13it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 30/134 [00:17<00:48,  2.15it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 31/134 [00:18<00:48,  2.12it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 32/134 [00:18<00:48,  2.11it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▍       | 33/134 [00:19<00:47,  2.13it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 34/134 [00:19<00:44,  2.24it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 35/134 [00:19<00:42,  2.34it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 36/134 [00:20<00:41,  2.37it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 45ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 37/134 [00:20<00:42,  2.29it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 40ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 38/134 [00:21<00:42,  2.25it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 42ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▉       | 39/134 [00:21<00:45,  2.09it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 41ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|██▉       | 40/134 [00:22<00:47,  1.99it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 51ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███       | 41/134 [00:23<00:48,  1.91it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███▏      | 42/134 [00:23<00:44,  2.08it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 43/134 [00:23<00:45,  2.02it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 44/134 [00:24<00:42,  2.10it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▎      | 45/134 [00:24<00:40,  2.17it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 46/134 [00:25<00:39,  2.23it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 47/134 [00:25<00:38,  2.27it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 48/134 [00:25<00:36,  2.38it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 49/134 [00:26<00:36,  2.32it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 50/134 [00:26<00:34,  2.40it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 51/134 [00:27<00:34,  2.42it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▉      | 52/134 [00:27<00:35,  2.28it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|███▉      | 53/134 [00:28<00:36,  2.25it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 54/134 [00:28<00:34,  2.31it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████      | 55/134 [00:29<00:34,  2.30it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 56/134 [00:29<00:34,  2.27it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 57/134 [00:29<00:33,  2.27it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 58/134 [00:30<00:33,  2.27it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 59/134 [00:30<00:32,  2.29it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▍     | 60/134 [00:31<00:33,  2.22it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 61/134 [00:31<00:33,  2.15it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▋     | 62/134 [00:32<00:34,  2.10it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 63/134 [00:32<00:33,  2.14it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 64/134 [00:33<00:31,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 42ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▊     | 65/134 [00:33<00:31,  2.22it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 40ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▉     | 66/134 [00:34<00:33,  2.06it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 37ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 67/134 [00:34<00:32,  2.07it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 42ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████     | 68/134 [00:35<00:32,  2.05it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 37ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████▏    | 69/134 [00:35<00:32,  2.00it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 70/134 [00:36<00:30,  2.07it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 71/134 [00:36<00:28,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▎    | 72/134 [00:36<00:28,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 73/134 [00:37<00:28,  2.12it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 74/134 [00:37<00:28,  2.10it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 75/134 [00:38<00:26,  2.22it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 76/134 [00:38<00:25,  2.29it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 77/134 [00:39<00:24,  2.30it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 78/134 [00:39<00:24,  2.29it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 59%|█████▉    | 79/134 [00:40<00:25,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|█████▉    | 80/134 [00:40<00:24,  2.24it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 81/134 [00:40<00:22,  2.35it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 61%|██████    | 82/134 [00:41<00:23,  2.25it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 83/134 [00:41<00:22,  2.25it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 84/134 [00:42<00:21,  2.34it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 85/134 [00:42<00:19,  2.50it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 86/134 [00:42<00:18,  2.56it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▍   | 87/134 [00:43<00:19,  2.47it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 88/134 [00:43<00:20,  2.28it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▋   | 89/134 [00:44<00:20,  2.22it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 90/134 [00:44<00:18,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 91/134 [00:45<00:18,  2.31it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▊   | 92/134 [00:45<00:18,  2.26it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 48ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 93/134 [00:46<00:18,  2.23it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 43ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 94/134 [00:46<00:19,  2.01it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 37ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████   | 95/134 [00:47<00:19,  1.99it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 44ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 96/134 [00:47<00:19,  1.95it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 39ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 97/134 [00:48<00:19,  1.92it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 44ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 98/134 [00:48<00:18,  1.98it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 99/134 [00:49<00:16,  2.11it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▍  | 100/134 [00:49<00:15,  2.15it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 101/134 [00:50<00:15,  2.13it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 102/134 [00:50<00:14,  2.21it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 103/134 [00:50<00:13,  2.24it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 104/134 [00:51<00:14,  2.13it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 105/134 [00:51<00:12,  2.25it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▉  | 106/134 [00:52<00:12,  2.31it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|███████▉  | 107/134 [00:52<00:11,  2.26it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████  | 108/134 [00:53<00:11,  2.27it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████▏ | 109/134 [00:53<00:11,  2.18it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 110/134 [00:54<00:11,  2.12it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 111/134 [00:54<00:10,  2.11it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▎ | 112/134 [00:55<00:10,  2.13it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 113/134 [00:55<00:09,  2.25it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 114/134 [00:55<00:08,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 115/134 [00:56<00:08,  2.33it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 116/134 [00:56<00:07,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 117/134 [00:57<00:07,  2.34it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 118/134 [00:57<00:06,  2.42it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▉ | 119/134 [00:57<00:06,  2.47it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|████████▉ | 120/134 [00:58<00:05,  2.34it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 42ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 121/134 [00:59<00:06,  2.09it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 38ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████ | 122/134 [00:59<00:05,  2.13it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 38ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 123/134 [01:00<00:05,  2.02it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 37ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 124/134 [01:00<00:04,  2.02it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 41ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 125/134 [01:01<00:04,  1.95it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 126/134 [01:01<00:04,  1.97it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▍| 127/134 [01:01<00:03,  2.14it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 128/134 [01:02<00:02,  2.16it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▋| 129/134 [01:02<00:02,  2.24it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 130/134 [01:03<00:01,  2.33it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 131/134 [01:03<00:01,  2.21it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▊| 132/134 [01:04<00:00,  2.30it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▉| 133/134 [01:04<00:00,  2.41it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 134/134 [01:04<00:00,  2.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.95239\n","F1: 0.81965\n","Jaccard: 0.71057\n","Recall: 0.89071\n","Precision: 0.78358\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nH2_4fPCmVQC","executionInfo":{"status":"ok","timestamp":1689441953846,"user_tz":-330,"elapsed":62,"user":{"displayName":"VANGA KANISHKA NADH","userId":"15191267719021947787"}}},"execution_count":5,"outputs":[]}]}